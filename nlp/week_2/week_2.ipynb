{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvmDD-lSyzf7"
   },
   "source": [
    "# Programming assignment. Week 2. Vector models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is graded by your `submission.json` which is created by a cell below. To generate your submission file you need to fill the values of **GRADING_ANSWER** instance fields.\n",
    "\n",
    "You can press **\"Submit Assignment\"** at any time to submit partial progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submit import Answer\n",
    "\n",
    "\n",
    "GRADING_ANSWER = Answer()\n",
    "GRADING_ANSWER.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment you will work with different embeddings. You will work with `gensim` library that provides the access and cinvenient usage of word2vec and fasttext models. On the sentiment task you will check how the vector embeddings work. \n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "7tSnqLDPc5Z-",
    "outputId": "329ca993-2386-4dc4-8a20-b00b1ab27759"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  With all this stuff going down at the moment w...\n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2          0  The film starts with a manager (Nicholas Bell)...\n",
       "3          0  It must be assumed that those who praised this...\n",
       "4          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, load the data for sentiment task and prepare the data.\n",
    "# Please, note, that these cells may have quite long runtime.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.read_csv('sentiment.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "SCSr2IJC3YKD",
    "outputId": "14f45f26-e669-4170-d0e2-a1db7892f517"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>with all this stuff going down at the moment w...</td>\n",
       "      <td>[with, all, this, stuff, going, down, at, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>the classic war of the worlds by timothy hines...</td>\n",
       "      <td>[the, classic, war, of, the, worlds, by, timot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>the film starts with a manager nicholas bell g...</td>\n",
       "      <td>[the, film, starts, with, a, manager, nicholas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>it must be assumed that those who praised this...</td>\n",
       "      <td>[it, must, be, assumed, that, those, who, prai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>superbly trashy and wondrously unpretentious s...</td>\n",
       "      <td>[superbly, trashy, and, wondrously, unpretenti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review  \\\n",
       "0          1  With all this stuff going down at the moment w...   \n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2          0  The film starts with a manager (Nicholas Bell)...   \n",
       "3          0  It must be assumed that those who praised this...   \n",
       "4          1  Superbly trashy and wondrously unpretentious 8...   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  with all this stuff going down at the moment w...   \n",
       "1  the classic war of the worlds by timothy hines...   \n",
       "2  the film starts with a manager nicholas bell g...   \n",
       "3  it must be assumed that those who praised this...   \n",
       "4  superbly trashy and wondrously unpretentious s...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [with, all, this, stuff, going, down, at, the,...  \n",
       "1  [the, classic, war, of, the, worlds, by, timot...  \n",
       "2  [the, film, starts, with, a, manager, nicholas...  \n",
       "3  [it, must, be, assumed, that, those, who, prai...  \n",
       "4  [superbly, trashy, and, wondrously, unpretenti...  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "tag_regexp = re.compile(\"<[^>]*>\")\n",
    "regex = re.compile(\"[A-Za-z-]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    text = re.sub(tag_regexp, '', text)\n",
    "    text = re.sub('\\s+', ' ',text)\n",
    "    text = re.sub(r'\\\\','', text)\n",
    "    text = text.lower().strip()\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "data['cleaned_review'] = data['review'].apply(words_only)\n",
    "data['tokenized'] = data['cleaned_review'].apply(lambda x: x.split())\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7_CtAmRQ86S",
    "outputId": "755596d7-779b-4784-de84-744e80cd4f60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7751    [back, when, alec, baldwin, and, kim, basinger...\n",
       "4154    [i, too, was, quite, astonished, to, see, how,...\n",
       "3881    [i, saw, this, film, for, the, very, first, ti...\n",
       "9238    [i, think, a, great, many, viewers, missed, en...\n",
       "5210    [this, is, a, taut, suspenseful, masterpiece, ...\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data on train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.tokenized, data.sentiment, test_size=0.2, random_state = 5)\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qxG5EeSeKls",
    "outputId": "9ae0b05e-521c-4f9e-8711-162f4b74295b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "jjeDOlfieNOP",
    "outputId": "eb86e986-1a16-4038-f6be-c4ff09d96a73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>with all this stuff going down at the moment w...</td>\n",
       "      <td>[with, all, this, stuff, going, down, at, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>the classic war of the worlds by timothy hines...</td>\n",
       "      <td>[the, classic, war, of, the, worlds, by, timot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>the film starts with a manager nicholas bell g...</td>\n",
       "      <td>[the, film, starts, with, a, manager, nicholas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>it must be assumed that those who praised this...</td>\n",
       "      <td>[it, must, be, assumed, that, those, who, prai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>superbly trashy and wondrously unpretentious s...</td>\n",
       "      <td>[superbly, trashy, and, wondrously, unpretenti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review  \\\n",
       "0          1  With all this stuff going down at the moment w...   \n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2          0  The film starts with a manager (Nicholas Bell)...   \n",
       "3          0  It must be assumed that those who praised this...   \n",
       "4          1  Superbly trashy and wondrously unpretentious 8...   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  with all this stuff going down at the moment w...   \n",
       "1  the classic war of the worlds by timothy hines...   \n",
       "2  the film starts with a manager nicholas bell g...   \n",
       "3  it must be assumed that those who praised this...   \n",
       "4  superbly trashy and wondrously unpretentious s...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [with, all, this, stuff, going, down, at, the,...  \n",
       "1  [the, classic, war, of, the, worlds, by, timot...  \n",
       "2  [the, film, starts, with, a, manager, nicholas...  \n",
       "3  [it, must, be, assumed, that, those, who, prai...  \n",
       "4  [superbly, trashy, and, wondrously, unpretenti...  "
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRrCqrNuTkAR"
   },
   "source": [
    "## BoW\n",
    "\n",
    "#### Bag of words\n",
    "\n",
    "Implement *bag-of-words* representation. To create this transformation, follow the steps:\n",
    "1. Find *N* most popular words in train corpus and numerate them. Do not count words which are in STOPWORDS. Now we have a dictionary of the most popular words.\n",
    "\n",
    "2. For each review in the corpora create a zero vector with the dimension equals to *N*.\n",
    "3. For each text in the corpora iterate over words which are in the dictionary and increase by 1 the corresponding coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_words = {}\n",
    "\n",
    "for _, tokens in X_train.iteritems():\n",
    "    for token in tokens:\n",
    "        if token not in STOPWORDS:\n",
    "            cnt = dict_words.setdefault(token, 1) + 1\n",
    "            dict_words[token] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "sorted_dict_words = OrderedDict(sorted(dict_words.items(), key = itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_SIZE = 500\n",
    "\n",
    "words_counts = list(sorted_dict_words.values())[:DICT_SIZE]\n",
    "WORDS_TO_INDEX = list(sorted_dict_words)[:DICT_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "id": "yEY1QA0zXP2V"
   },
   "outputs": [],
   "source": [
    "def BoW(words, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        words: a list of words\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    result_vector = [words.count(word) for word in words_to_index]\n",
    " \n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htDVE5g5V4ue",
    "outputId": "ee6e4133-fd8f-4ae4-f1d5-2f0419f3d554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (8000, 500)\n",
      "X_test shape  (2000, 500)\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "\n",
    "X_train_bow = sp_sparse.vstack([sp_sparse.csr_matrix(BoW(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_test_bow = sp_sparse.vstack([sp_sparse.csr_matrix(BoW(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
    "\n",
    "print('X_train shape ', X_train_bow.shape)\n",
    "print('X_test shape ', X_test_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eZCUzDkVnXm"
   },
   "source": [
    "**Task 1.1 (0.5 points).** For the 5th row in *X_train_bow* find how many non-zero elements it has. \n",
    "\n",
    "**Hint** Do not forget that indexes start with 0 and the first row has index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROW_IDX = 5\n",
    "\n",
    "non_zeros = sum([1 for x in range(0, DICT_SIZE) if X_train_bow[ROW_IDX-1, x] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bPIH_AASYQrq",
    "outputId": "37fe83a9-1ff2-499a-b7cf-18a69cfe526e"
   },
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q1 = non_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjIoEEchaHQ1"
   },
   "source": [
    "**Task 1.2 (0.5 points)** \n",
    "Train (on train set) `RandomForestClassifier` from `sklearn.ensemble` with `n_estimators = 300` and `random_state=5` and `max_depth = 5`. What is the accuracy score on test set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=300, random_state=5)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 300, random_state = 5, max_depth = 5)\n",
    "rf.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "id": "Jbf8h627anw5"
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test_bow)\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7715"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED PART, DO NOT CHANGE!\n",
    "GRADING_ANSWER.Q2 = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMCrbsvua2XX"
   },
   "source": [
    "## TF-IDF\n",
    "Now vectorize your texts using `TfidfVectorizer` from `sklearn.feature_extraction.text`.\n",
    "Pass `STOPWORDS` as `stop_words` and set `max_fetures = 500`.\n",
    "\n",
    "**Task 2 (0.5 points).** Train (on train set) `RandomForestClassifier` from `sklearn.ensemble` with `n_estimators = 300`, `random_state=5`, and `max_depth = 5` on tf-idf embeddings. What is the accuracy score on test set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words=STOPWORDS, max_features=500, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidfvectorizer.fit_transform(X_train.to_list())\n",
    "X_test_tfidf = tfidfvectorizer.fit_transform(X_test.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=300, random_state=5)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 300, random_state = 5, max_depth = 5)\n",
    "rf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "id": "Q4McPgAbbjXr"
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5955"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED PART, DO NOT CHANGE!\n",
    "GRADING_ANSWER.Q3 = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tgqd5oQOcAXl"
   },
   "source": [
    "## Distributional embeddings\n",
    "\n",
    "Let us use a few pre-trained distributional embedding models to analyze the performance of the classifier:\n",
    "\n",
    "*   ```word2vec```\n",
    "*   ```fastText```\n",
    "\n",
    "We will use the [```Gensim```](https://radimrehurek.com/gensim_3.8.3/) library for python which provides a wide range of useful functions and pre-trained embedding models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz0hGB1le0d-"
   },
   "source": [
    "### Vector models. ```word2vec```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yGoA1VQ4v9I"
   },
   "source": [
    "In this assignment you are going to work with the pretrined model. The file `GoogleNews-vectors-negative300.bin` **is already located in the root directory**. \n",
    "\n",
    "You may also download it using the code below, or you may directly download it from [here](https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2PUKpwFub4e",
    "outputId": "e38e8be5-92f2-4999-c3c1-9bad211a39c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: brew: not found\n",
      "--2021-07-20 16:25:34--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving proxy-coursera-apps.org (proxy-coursera-apps.org)... 10.0.0.170\n",
      "Connecting to proxy-coursera-apps.org (proxy-coursera-apps.org)|10.0.0.170|:3128... connected.\n",
      "Proxy tunneling failed: ForbiddenUnable to establish SSL connection.\n",
      "gzip: GoogleNews-vectors-negative300.bin.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# CODE FOR DOWNLOADING PRETRAINED MODEL [local usage only]\n",
    "!brew install wget\n",
    "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "!gzip -d GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LO0cxQGn5kjw"
   },
   "source": [
    "**Task 3.1 (0.5 points)**\n",
    "\n",
    "Load word2vec model using `gensim.models.KeyedVectors.load_word2vec_format`. How many words in model vocabulary start with `a` or `A`? (In the answer write the sum of vocabulary words wich start with `a` and with `A`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ABzWu1I4RSi",
    "outputId": "3c4b3554-57d8-469b-b369-4f8319e248d9"
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "## YOUR CODE HERE\n",
    "\n",
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q4 = 0 ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IRu2sMEDTVy"
   },
   "source": [
    "**Task 3.2 (0.5 points)**\n",
    "Select all words from the vocabulary, which start from `z` or `Z`. Among these words which is the most similar to the word `park`?\n",
    "\n",
    "Use `sklearn.metrics.pairwise.cosine_similarity` as a similarity measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pc4Er6AtD6gC",
    "outputId": "70d31012-eb2e-4652-99bc-ead47c07d150"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'most_common'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-364-32692b32f5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mwords_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m## YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mwords_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'most_common'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import collections\n",
    "\n",
    "\n",
    "## YOUR CODE HERE\n",
    "words_counts = ['a', 'b'] ## YOUR CODE HERE\n",
    "words_counts.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q5 = 0 ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAVnMJNQSzio"
   },
   "source": [
    "**Task 3.3 (0.5 points)** \n",
    "Compute top-5 most frequent words in `X_train` without counting words from `STOPWORDS`.\n",
    "In answer write top-5 words in one string separating words by spaces.\n",
    "\n",
    "**Example answer:** `\"cat dom apple home house\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pzx3aXJvbWn3"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "words_counts = ## YOUR CODE HERE\n",
    "answer = ' '.join([x[0] for x in words_counts.most_common(5)])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "tg0WEI0MRfM8",
    "outputId": "63288196-e6cb-4a9f-c921-bfda1292ac05"
   },
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q6 = 0 ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKTZwtAV2Qyd"
   },
   "source": [
    "**Task 3.4 (0.5 points)**. With word2vec embeddings you can perform different linear operations. For example, you can check which of the words do not belong in the sequence (or does not match), or what vector we get if we sum of the `king` and the `woman` vectors and subtract the vector `man`. For the model above, do the following operations: \n",
    "\n",
    "1) what word from these: `London Warsaw Peru Kiev`\n",
    "does not match; \n",
    "\n",
    "2) take the word from step 1 and make linear operation `Moscow + <your word> - Russia`; \n",
    "\n",
    "3) for the word from step 2 write the score for most simliar one. Round the answer up to 2 digits after the decimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IL7Fuv5u0cDt",
    "outputId": "7ea5e44b-40f9-45e8-e63c-dfeeb900ae74"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q7 = 0 ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfDcaWER4yI5"
   },
   "source": [
    "**Task 3.5 (0.5 point).** Add information in the pre-trained word2vec model. We have already pre-trained word2vec model, but what if we want to add some new information inside and increse the occurance of some words. You can update the parameters using the gensim interface, you may find more information [here](https://radimrehurek.com/gensim/models/keyedvectors.html). Note, that KeyedVectors does not working, you can update only the full model.  \n",
    "\n",
    "First, take the tokenized sentences from sentiment data and train Word2Vec model. Set parameters: vector_size=100, window=2, min_count=1, workers=1. Write the most similar word for the woman vector for trained model and its similarity score (round the answer up to 4 digits after the decimal point). \n",
    "\n",
    "Answer format is a string with a word and the corresponding similarity score separated by space.\n",
    "\n",
    "Example answer: `\"girl 0.5123\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1ZaxiCIT5Y0"
   },
   "outputs": [],
   "source": [
    "sentences = [line for line in data.tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q8 = 'girl 0.5123' ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r_qv0kN9p7N"
   },
   "source": [
    "**Task 3.6 (0.5 point)**. Next, we will learn how to update parameters of the model with new sentences. \n",
    "\n",
    "\n",
    "Let's take some data from Alice’s Adventures in Wonderland by Lewis Carroll and add new texts in the model. First, load the data and prepare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9eztO5fl9xVs",
    "outputId": "88b0b4ae-581d-4c70-ca68-855e9bc6e5d0"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "with open(\"alice.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = re.sub('\\n', ' ', text)\n",
    "sents = nltk.sent_tokenize(text.lower())\n",
    "\n",
    "punct = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~„“«»†*—/\\-‘’'\n",
    "clean_sents = []\n",
    "\n",
    "for sent in sents:\n",
    "    s = [w.lower().strip(punct) for w in sent.split()]\n",
    "    clean_sents.append(s)\n",
    "\n",
    "print(clean_sents[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTagjJOL-mzh"
   },
   "source": [
    "You need to save the current model in the right format, load again the full model and add new texts in it. Run with default parameters 5 epochs. After, again check the most similar words for `woman` and write the word and score. Round the answer up to 4 digits after the decimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1R0_KgN-iT-",
    "outputId": "9e442d03-936b-41ea-9d8e-bbf623f568a1"
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q9 = 0 ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXS2pRfQtG-M"
   },
   "source": [
    "### Pooling methods\n",
    "\n",
    "Once we have a word embedding model, how can we get from word embeddings to document embeddings?\n",
    "\n",
    "For this, there are several *pooling* strategies that define the way to aggregate the embeddings of each word in a document by taking an element-wise **average**, **minimum**, **maximum** or **sum**:\n",
    "\n",
    "*   **Mean-pooling** (**average-pooling**)\n",
    "*   **Min-pooling**\n",
    "*   **Max-pooling**\n",
    "*   **Sum-pooling**\n",
    "\n",
    "It is very common in practice to use mean-pooled document embeddings for the downstream task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8DPqZm278AM"
   },
   "source": [
    "**Task 4.1 (1 point).**\n",
    "Using the model build sentence embedder, which computes the sentence vector as the mean vector of its word vectors (**mean-pooling**). Use zero vectors for out of vocabulary words.\n",
    "\n",
    "What is the embedding for the sentence `'the cat sat on the mat'`?\n",
    "Tokenize the sentence splitting it by spaces.\n",
    "\n",
    "In the asnwer write the mean of its components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTn9zug-75UE"
   },
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = ## YOUR CODE HERE\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X is a list of tokenized sentences \n",
    "        # example:\n",
    "        # X = [['the','cat,'sat','on','the','mat'],\n",
    "        #      ['the','dog,'lies','on','the','sofe']]\n",
    "        \n",
    "        ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3B80FYRCU5R"
   },
   "outputs": [],
   "source": [
    "vectorizer = MeanEmbeddingVectorizer(model)\n",
    "cat_vector = ### YOUR CODE HERE\n",
    "print(cat_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q10 = 0 ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcoUP5t2IKuH"
   },
   "source": [
    "**Task 4.2 (1 point).** Using `MeanEmbeddingVectorizer` vectorize tokenized reviews. Than train (on train set) `RandomForestClassifier` from `sklearn.ensemble` with `n_estimators = 300` and `random_state=5`.\n",
    "What is the accuracy score on test set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2V1EPt44-U-a",
    "outputId": "d5bcb826-afcd-4996-fb02-fcf40f38f109"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "pred = ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q11 = 0 ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osif4smXdymV"
   },
   "source": [
    "**Task 4.3 (1 point)**\n",
    "Transform `MeanEmbeddingVectorizer` for into MinEmbeddingVectorizer, \n",
    "MaxEmbeddingVectorizer, and SumEmbeddingVectorizer. \n",
    "\n",
    "For each of the vectorizers:\n",
    "\n",
    "\n",
    "1) vectorize the data\n",
    "\n",
    "\n",
    "2) train (on train set) `RandomForestClassifier` from `sklearn.ensemble` with `n_estimators = 300` and `random_state=5`.\n",
    "\n",
    "\n",
    "3) compute accuracy score on test set\n",
    "\n",
    "What method among three is the best? The answer should be of three: \"min\", \"max\", \"sum\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psuVdEZxfJML"
   },
   "outputs": [],
   "source": [
    "### YOU CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPSoYVZJfLW1"
   },
   "outputs": [],
   "source": [
    "class EmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = model[model.index_to_key[0]].shape[0]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, type_ = 'min'):\n",
    "        # X is a list of tokenized sentences \n",
    "        # example:\n",
    "        # X = [['the','cat,'sat','on','the','mat'],\n",
    "        #      ['the','dog,'lies','on','the','sofe']]\n",
    "        \n",
    "        ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaLQ2i8If1QJ",
    "outputId": "622786a6-647f-46e2-a6b9-69d062cc5219"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for type_ in ['min', 'max', 'sum']:\n",
    "  ### YOUR CODE HERE\n",
    "  results.append([type_, accuracy])\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q12 = 0 ## YOUR ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAaSJlQ9hApg"
   },
   "source": [
    "**Task 4.4 (0.5 points)** What is the accuracy score for this method?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iL8ZL1dhKVE"
   },
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q13 = 0 ## YOUR ACCURACY SCORE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCqr1vS5k4mw"
   },
   "source": [
    "## Text classification with ```fastText```\n",
    "\n",
    "Let us have a look at how we can use the ```fastText``` library for text classification. Specifically, the [library](https://github.com/facebookresearch/fastText#text-classification) can be used to train superrvised text classifiers, for example for sentiment analysis in a single command:\n",
    "\n",
    "```./fasttext supervised -input train.txt -output model```, where ```train.txt``` is the train set with annotated examples for the task, and ```model``` is a name of your model that will be saved in 2 files: ```model.bin``` and ```model.vec```.\n",
    "\n",
    "**Data format**: \n",
    "The train file should be in a specified format, containing a training sentence or document per line along with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aCt8e2DmJxf"
   },
   "outputs": [],
   "source": [
    "## Install fasttext if you work in Colab (otherwise it is already installed)\n",
    "\n",
    "# !wget https://github.com/facebookresearch/fastText/archive/v0.2.0.zip\n",
    "# !unzip v0.2.0.zip\n",
    "# %cd fastText-0.2.0\n",
    "# !make\n",
    "# !pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-j39XPKnvOF"
   },
   "source": [
    "Let us prepare the data in the required format as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oc3H-FxT8cXT",
    "outputId": "16cec31f-f24a-4c93-eda6-3ef7e6f22a67"
   },
   "outputs": [],
   "source": [
    "X = [sentence.strip() for sentence in data.cleaned_review]\n",
    "y = [str(label) for label in data.sentiment]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 5)\n",
    "\n",
    "with open('ft_train.txt', 'w') as outfile:\n",
    "    for i in range(len(X_train)):\n",
    "        outfile.write('__label__' + y_train[i] + ' '+ X_train[i] + '\\n')\n",
    "    \n",
    "with open('ft_test.txt', 'w') as outfile:\n",
    "    for i in range(len(X_test)):\n",
    "        outfile.write('__label__' + y_test[i] + ' ' + X_test[i] + '\\n')\n",
    "\n",
    "print(\"Files are written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3A56kSl_KTP",
    "outputId": "77638f99-2ea8-40ba-dd50-2aca46d1a2b5"
   },
   "outputs": [],
   "source": [
    "!head -n 5 ft_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xnu85-injhQP"
   },
   "source": [
    "### ```fastText```\n",
    "\n",
    "Let us have a look at how we can apply a pre-trained fastText model that was trained over different text corpora: Wikipedia, UMBC Webbase corpus and statmt.org news dataset (16B tokens in total!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjI10L3xqNKA"
   },
   "source": [
    "**Task 5.1 (1 point).** Train fasttext model! Set default parapmeters, but train it for 20 epochs! \n",
    "\n",
    "How can we now evaluate the model now? Enter the code to test the model on the ```ft_test.txt``` file with the help of the ```fastText``` library. Write Precision (P@1) and recall (R@1) **scores**. Round the answer up to 3 digits after the decimal point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSdc0iRjCdyD",
    "outputId": "09918ba0-5f70-4fd6-c364-8ebf30e90e8a"
   },
   "outputs": [],
   "source": [
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93BqrfenAu_2"
   },
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q14 = 0 ## YOUR PRECISION VALUE HERE\n",
    "GRADING_ANSWER.Q15 = 0 ## YOUR RECALL VALUE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gr9dzWClqm3-"
   },
   "source": [
    "We can also load the model and use the python code to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giUXoSCtqi7i",
    "outputId": "1db58d8c-7c58-4997-a160-f4a65d287a94"
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "## save trained model\n",
    "classifier.save_model(\"sentiment_model.bin\")\n",
    "## load our trained classifier\n",
    "sentiment_ft = fasttext.load_model(\"sentiment_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjCzHdT0rK9P"
   },
   "source": [
    "**Task 5.2. (1 point)** Write a code to make a prediction with the classifier. As answer write the label (1 or 0) and the confidence score (Round the answer up to 3 digits after the decimal point.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbROKE7RrEOb",
    "outputId": "99460bef-f642-4a32-a665-b67df4953c64"
   },
   "outputs": [],
   "source": [
    "review = \"This was such a great film! I am so lucky to watch it.\"\n",
    "\n",
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyaQAEEVBoYL"
   },
   "outputs": [],
   "source": [
    "## GRADED PART, PUT YOUR ANSWER HERE\n",
    "GRADING_ANSWER.Q16 = '' ## YOUR LABEL HERE\n",
    "GRADING_ANSWER.Q17 = 0 ## YOUR CONFIDENCE SCORE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗️Remember to **run the first code cell again** before submitting the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFI2qi0-loU_"
   },
   "source": [
    "### Extra. Ungraded. Extrinsic evaluation\n",
    "\n",
    "Train a few embedding models using various text corpora from the ```Gensim``` library. Set different hyperparameters for training, and compare the models by fixing the sentiment classifier hyperparameters. Analyze the performance of the classifiers trained over your embedding models. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SXS2pRfQtG-M"
   ],
   "name": "week_2.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "YaXXR2iwQ9al10dosHPW1A"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
