{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hometask-task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWBmnf6vzGnA"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTZLdoNWzPkl"
      },
      "source": [
        "torchvision model tuning\n",
        "------------------------------\n",
        "\n",
        "In this task you will have to run all the steps of the lab and save final model weights into `final_model.pt` file, which you will have to submit as the result of your work into Coursera Lab environment by clicking Submit Assignment button.\n",
        "\n",
        "Part of the steps are complete, others will require you to do simple excercises.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl5X76W-zRg9"
      },
      "source": [
        "https://pytorch.org/docs/stable/torchvision/models.html - models trained on ImageNet\n",
        "\n",
        "First we get the pre-trained model and then use feature extraction for final layers training.\n",
        "\n",
        "Steps:\n",
        "-  get data\n",
        "-  init pre-trained model\n",
        "-  add new head layer, change output shape for desired dataset\n",
        "-  define how we train our model (update only final layers or all)\n",
        "-  train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SppDHWWYzfz9"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RdqHTllzkih"
      },
      "source": [
        "Data\n",
        "------\n",
        "\n",
        "We will use *hymenoptera_data*: https://download.pytorch.org/tutorial/hymenoptera_data.zip.\n",
        "It has 2 classes - bees and ants.\n",
        "To get data we will use class ImageFolder - https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder\n",
        "\n",
        "As a model we take vgg11_bn - VGG11 trained with batch normalization\n",
        "\n",
        "Other params:\n",
        "batch_size - size of the batch, num_classes - amount of different classes in data, num_epochs - how many epochs to train for, finetune - flag to determine if we train only last layers or the whole model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwPcipclzhgf"
      },
      "source": [
        "! wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "! mkdir data\n",
        "! unzip hymenoptera_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65A4xlhVzsiv"
      },
      "source": [
        "! mv hymenoptera_data data/\n",
        "! ls ./data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1qbJbH4zwtd"
      },
      "source": [
        "data_dir = \"./data/hymenoptera_data\" # path to data\n",
        "num_classes = 2                      # amount of classes in new data\n",
        "\n",
        "batch_size = 8                       # data batch size\n",
        "num_epochs = 5                       # epochs count\n",
        "feature_extract = True               # should we train with feature extraction (last layers fine tuning)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMrLK46tzzZR"
      },
      "source": [
        "Model training\n",
        "---------------\n",
        "\n",
        "And helper for layers params setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw9DIznqzxp4"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
        "    start = time.time()\n",
        "    _hist = []\n",
        "    best_model = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            model.train() if phase == 'train' else model.eval()\n",
        "            _loss, _acc = 0.0, 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                _loss += loss.item() * inputs.size(0)\n",
        "                _acc += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = _loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = _acc.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.6f} Acc: {:.6f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val':\n",
        "                _hist.append(epoch_acc)\n",
        "                if epoch_acc > best_acc:\n",
        "                  best_acc = epoch_acc\n",
        "                  best_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - start\n",
        "    print('Training finished: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Validation: best score Accuracy: {:6f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model)\n",
        "    return model, _hist\n",
        "\n",
        "\n",
        "def set_requires_grad(model, feature_extract):\n",
        "    if feature_extract:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw2OWAp8z5Aq"
      },
      "source": [
        "Model init and update\n",
        "-----------------------------------\n",
        "\n",
        "For more details - https://pytorch.org/docs/stable/torchvision/models.html\n",
        "\n",
        "In this block we change model's final layer. It is hard to automate this step, as each model has its own characteristics. Last layer of CNN model (usually fully conntected) has the same amount of outputs as the dataset classes. All models in torchvision are trained on Imagenet, so the size of the final layer is 1000.\n",
        "\n",
        "Our goal - get the final layer to have the same inputs amount and change amount of outputs to satisfy the requirements of new dataset.\n",
        "\n",
        "Important notice to distinguish retraining and feature extraction (final layers training, finetuning): in the last case we want to update only final layer (layers), meaning we ignore gradients calculation for the previous layers, in order to do so we set `required_grad=False` parameter of the layers. By default, the parameter is `True` (including newly created layer, but we do want to update it, that is why we do not set that param for the new layer).\n",
        "\n",
        "VGG\n",
        "---\n",
        "\n",
        "More details about the model - https://arxiv.org/pdf/1409.1556.pdf\n",
        "\n",
        "In torchvision library there is 8 versions of pre-trained VGG model with different size and batch-normalization usage. We will use VGG-11 with batch-normalization.\n",
        "\n",
        "In model description we can see: classifier (model's head) includes final layer - Linear with 4096 input params and 1000 outputs:.\n",
        "```\n",
        "   (classifier): Sequential(\n",
        "       ...\n",
        "       (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
        "    )\n",
        "```\n",
        "We can change it by using following code:\n",
        "\n",
        "`model.classifier[6] = nn.Linear(4096,num_classes)`\n",
        "\n",
        "We update sixth (last) layer in classifier block of model's layers sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLU773m3z5nA"
      },
      "source": [
        "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
        "    model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "    \n",
        "    set_requires_grad(model_ft, feature_extract)\n",
        "\n",
        "    num_ftrs = model_ft.classifier[6].in_features\n",
        "\n",
        "    model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    input_size = 224\n",
        "    \n",
        "    return model_ft, input_size\n",
        "\n",
        "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy-LjbTw0URv"
      },
      "source": [
        "Data loader\n",
        "---------\n",
        "\n",
        "Now knowing input data params we can init data loader.\n",
        "Important notice: models are trained with normalization values, details - https://pytorch.org/docs/master/torchvision/models.html\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYOaFDa80TuD"
      },
      "source": [
        "# Data normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                            data_transforms[x])\n",
        "    for x in ['train', 'val']\n",
        "}\n",
        "dataloaders_dict = {\n",
        "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=4)\n",
        "    for x in ['train', 'val']\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc2Lr1U20clc"
      },
      "source": [
        "Init optimizer\n",
        "--------------------\n",
        "\n",
        "Now we have model and data, last thing left is to create optimizer, which will update only required params. We already specified `required_grad` param before.\n",
        "\n",
        "We have to pass those (and only those) params into SGD for optimization\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0EifNXg0dLY"
      },
      "source": [
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters() # all params by default\n",
        "print(\"Params to update while training:\")\n",
        "\n",
        "if feature_extract:\n",
        "    # only last layer, update the list\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    # all params, just output\n",
        "    for name, param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.002, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObGQd6As1GXB"
      },
      "source": [
        "Training and validation\n",
        "--------------------------------\n",
        "\n",
        "Now we have to determine loss function and start training process for specified amount of epochs. CPU learning might require some time (depending on the model), and learning rate could be optimized as well (as it is not optimal by default).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlAlwJ3o1Gyg",
        "outputId": "52cad80f-71bc-4283-b841-6e20debad56f"
      },
      "source": [
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# training\n",
        "# TODO: call train_model will all required params:\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.374047 Acc: 0.807377\n",
            "val Loss: 0.144770 Acc: 0.960784\n",
            "Epoch 1/24\n",
            "train Loss: 0.177782 Acc: 0.926230\n",
            "val Loss: 0.154126 Acc: 0.934641\n",
            "Epoch 2/24\n",
            "train Loss: 0.203547 Acc: 0.909836\n",
            "val Loss: 0.134668 Acc: 0.947712\n",
            "Epoch 3/24\n",
            "train Loss: 0.231375 Acc: 0.905738\n",
            "val Loss: 0.125119 Acc: 0.941176\n",
            "Epoch 4/24\n",
            "train Loss: 0.163230 Acc: 0.922131\n",
            "val Loss: 0.109707 Acc: 0.947712\n",
            "Epoch 5/24\n",
            "train Loss: 0.215465 Acc: 0.930328\n",
            "val Loss: 0.140373 Acc: 0.934641\n",
            "Epoch 6/24\n",
            "train Loss: 0.149236 Acc: 0.926230\n",
            "val Loss: 0.173948 Acc: 0.928105\n",
            "Epoch 7/24\n",
            "train Loss: 0.174040 Acc: 0.922131\n",
            "val Loss: 0.189856 Acc: 0.921569\n",
            "Epoch 8/24\n",
            "train Loss: 0.188477 Acc: 0.938525\n",
            "val Loss: 0.176673 Acc: 0.934641\n",
            "Epoch 9/24\n",
            "train Loss: 0.133974 Acc: 0.938525\n",
            "val Loss: 0.151183 Acc: 0.941176\n",
            "Epoch 10/24\n",
            "train Loss: 0.218024 Acc: 0.905738\n",
            "val Loss: 0.159795 Acc: 0.934641\n",
            "Epoch 11/24\n",
            "train Loss: 0.193587 Acc: 0.930328\n",
            "val Loss: 0.171715 Acc: 0.941176\n",
            "Epoch 12/24\n",
            "train Loss: 0.164147 Acc: 0.954918\n",
            "val Loss: 0.154225 Acc: 0.947712\n",
            "Epoch 13/24\n",
            "train Loss: 0.224155 Acc: 0.901639\n",
            "val Loss: 0.163625 Acc: 0.941176\n",
            "Epoch 14/24\n",
            "train Loss: 0.214380 Acc: 0.918033\n",
            "val Loss: 0.181106 Acc: 0.915033\n",
            "Epoch 15/24\n",
            "train Loss: 0.183227 Acc: 0.901639\n",
            "val Loss: 0.206471 Acc: 0.915033\n",
            "Epoch 16/24\n",
            "train Loss: 0.249373 Acc: 0.922131\n",
            "val Loss: 0.147424 Acc: 0.941176\n",
            "Epoch 17/24\n",
            "train Loss: 0.103400 Acc: 0.942623\n",
            "val Loss: 0.150000 Acc: 0.941176\n",
            "Epoch 18/24\n",
            "train Loss: 0.156180 Acc: 0.946721\n",
            "val Loss: 0.147307 Acc: 0.934641\n",
            "Epoch 19/24\n",
            "train Loss: 0.141183 Acc: 0.950820\n",
            "val Loss: 0.171721 Acc: 0.954248\n",
            "Epoch 20/24\n",
            "train Loss: 0.128547 Acc: 0.934426\n",
            "val Loss: 0.139169 Acc: 0.941176\n",
            "Epoch 21/24\n",
            "train Loss: 0.193393 Acc: 0.913934\n",
            "val Loss: 0.141395 Acc: 0.928105\n",
            "Epoch 22/24\n",
            "train Loss: 0.179921 Acc: 0.942623\n",
            "val Loss: 0.179447 Acc: 0.921569\n",
            "Epoch 23/24\n",
            "train Loss: 0.311884 Acc: 0.893443\n",
            "val Loss: 0.153891 Acc: 0.928105\n",
            "Epoch 24/24\n",
            "train Loss: 0.193056 Acc: 0.938525\n",
            "val Loss: 0.156871 Acc: 0.928105\n",
            "Training finished: 52m 29s\n",
            "Validation: best score Accuracy: 0.960784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EslonYsA1cNE"
      },
      "source": [
        "torch.save(model_ft.state_dict(), 'final_model.pt')"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}