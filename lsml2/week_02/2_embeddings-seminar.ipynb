{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text vector representations (embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13850</th>\n",
       "      <td>78.0</td>\n",
       "      <td>Magical Spanish villa tucked away on a palm tree-lined street in Silver Lake. The bedroom has  french doors which open to a tranquil, lush garden and it has it's own private bathroom. Just walking distance to Sunset Blvd. and the best of Silver Lake This 2 bedroom, 2 bath house has a wonderful indoor/outdoor flow. Hardwood floors, coved ceilings, built-ins, vintage-style baths and a beautiful fireplace make this a very unique and comfortable space. The guest room for rent has wonderful natural light and looks out on a private, dense garden. It faces west, so it is amazing during the sunset! The room has a queen-size bed, a spacious walk-in closet and it's own, private bathroom with a bathtub. The galley kitchen has all of the amenities, a breakfast nook and it opens up to the magical b...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7043</th>\n",
       "      <td>249.0</td>\n",
       "      <td>This nice one bedroom apartment is newly renovated and located only two blocks from the French quarter with free street parking. It is part of a historic mansion built in 1855 and located on the historic Esplanade Ave with 10ft ceilings throughout. Walking distance to all French Quarter festivities. The court yard and all of apt #3. As much as you'd like. I'm there if you need me and not if you don't. The mansions on Esplanade Ave is an attraction to tourism. During carnival and festival season you'll enjoy a short scenic wall to the cities heart of history and festivities. The other direction is a 2 miles straight shot to New Orleans City Park where you can enjoy kayaking, bike trails, golf, fishing, tennis and much more. This apartment is conveniently located two blocks from the Fren...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40442</th>\n",
       "      <td>60.0</td>\n",
       "      <td>Hello Everyone! my name is Ester, my boyfriend Antoine and I have lived in our studio for almost one year. We both moved from outside of California for work. You will enjoy staying at our place! It is situated in an excellent area where all the buzz is happening on Venice! You''ll see many people riding their bikes, cars with surf boards, and palm trees everywhere! The weather is perfect year round. The scenery is beautiful filled with flowers  and the streets are filled with artistic murals. Our studio is a perfect little space with a full kitchen at your disposal. We have a full size bed as well as space for an air mattress (which we can provide) as well. You will have access to the pool and hot tub to relax at any time and our bikes (2) are also available to use. At night you can me...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41512</th>\n",
       "      <td>150.0</td>\n",
       "      <td>Second floor room with double bed TV, Cable, Internet in private house with front and back yard. Private in ground pool, grill, etc. In the heart of Beach zone of Staten Island, Brooklyn, Rockaways, Long Island, Jersey Shore. Surfs up!!!</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56198</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Room available in a lovely terraced house in Mile End. Lovely people and lovely neighborhood. Close to Victoria Park, shoreditch and Olympic Park.  15 mins by tube or bus to central London.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Description lang\n",
       "13850   78.0  Magical Spanish villa tucked away on a palm tree-lined street in Silver Lake. The bedroom has  french doors which open to a tranquil, lush garden and it has it's own private bathroom. Just walking distance to Sunset Blvd. and the best of Silver Lake This 2 bedroom, 2 bath house has a wonderful indoor/outdoor flow. Hardwood floors, coved ceilings, built-ins, vintage-style baths and a beautiful fireplace make this a very unique and comfortable space. The guest room for rent has wonderful natural light and looks out on a private, dense garden. It faces west, so it is amazing during the sunset! The room has a queen-size bed, a spacious walk-in closet and it's own, private bathroom with a bathtub. The galley kitchen has all of the amenities, a breakfast nook and it opens up to the magical b...   en\n",
       "7043   249.0  This nice one bedroom apartment is newly renovated and located only two blocks from the French quarter with free street parking. It is part of a historic mansion built in 1855 and located on the historic Esplanade Ave with 10ft ceilings throughout. Walking distance to all French Quarter festivities. The court yard and all of apt #3. As much as you'd like. I'm there if you need me and not if you don't. The mansions on Esplanade Ave is an attraction to tourism. During carnival and festival season you'll enjoy a short scenic wall to the cities heart of history and festivities. The other direction is a 2 miles straight shot to New Orleans City Park where you can enjoy kayaking, bike trails, golf, fishing, tennis and much more. This apartment is conveniently located two blocks from the Fren...   en\n",
       "40442   60.0  Hello Everyone! my name is Ester, my boyfriend Antoine and I have lived in our studio for almost one year. We both moved from outside of California for work. You will enjoy staying at our place! It is situated in an excellent area where all the buzz is happening on Venice! You''ll see many people riding their bikes, cars with surf boards, and palm trees everywhere! The weather is perfect year round. The scenery is beautiful filled with flowers  and the streets are filled with artistic murals. Our studio is a perfect little space with a full kitchen at your disposal. We have a full size bed as well as space for an air mattress (which we can provide) as well. You will have access to the pool and hot tub to relax at any time and our bikes (2) are also available to use. At night you can me...   en\n",
       "41512  150.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Second floor room with double bed TV, Cable, Internet in private house with front and back yard. Private in ground pool, grill, etc. In the heart of Beach zone of Staten Island, Brooklyn, Rockaways, Long Island, Jersey Shore. Surfs up!!!   en\n",
       "56198   34.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Room available in a lovely terraced house in Mile End. Lovely people and lovely neighborhood. Close to Victoria Park, shoreditch and Olympic Park.  15 mins by tube or bus to central London.   en"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"airbnb-eng.tsv\", delimiter='\\t')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81406"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byte Pair Encoding\n",
    "\n",
    "First, let's apply compression method - byte pair encoding. We will use sentencepiece framework by Google: it is provided with python mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the first sentence\r\n",
      "and this is the second\r\n",
      "bla bla bla\r\n",
      "the end"
     ]
    }
   ],
   "source": [
    "! cat sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁this', 'is', 'a', 'te', 'st', 'bla', 'bla', 'bla']\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train('--input=sample.txt --model_prefix=sample_model --vocab_size=64 --character_coverage=1.0 --model_type=bpe')\n",
    "sp_bpe = spm.SentencePieceProcessor()\n",
    "sp_bpe.load('sample_model.model')\n",
    "\n",
    "print(sp_bpe.encode_as_pieces('thisisatestblablabla'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is \"encoded\" data.\n",
    "\n",
    "Sentencepiece can be run from CLI as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(79) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: sample.txt\n",
      "  input_format: \n",
      "  model_prefix: sample_model\n",
      "  model_type: BPE\n",
      "  vocab_size: 64\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(320) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(175) LOG(INFO) Loading corpus: sample.txt\n",
      "trainer_interface.cc(376) LOG(INFO) Loaded all 4 sentences\n",
      "trainer_interface.cc(391) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(391) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(391) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(396) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(457) LOG(INFO) all chars count=70\n",
      "trainer_interface.cc(478) LOG(INFO) Alphabet size=15\n",
      "trainer_interface.cc(479) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(511) LOG(INFO) Done! preprocessed 4 sentences.\n",
      "trainer_interface.cc(517) LOG(INFO) Tokenizing input sentences with whitespace: 4\n",
      "trainer_interface.cc(527) LOG(INFO) Done! 9\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1 size=20 all=55 active=40 piece=ent\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=0 size=40 all=42 active=27 piece=se\n",
      "trainer_interface.cc(605) LOG(INFO) Saving model: sample_model.model\n",
      "trainer_interface.cc(616) LOG(INFO) Saving vocabs: sample_model.vocab\n"
     ]
    }
   ],
   "source": [
    "! spm_train --input=sample.txt --model_prefix=sample_model --vocab_size=64 --character_coverage=1.0 --model_type=bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁this ▁is ▁a ▁ te st ▁bla bla bla .\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"this is a test blablabla.\" | spm_encode --model=sample_model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply BPE to our Airbnb dataset: to do so we have to first reformat raw (important! preprocessing and tokenisation are performed within the framework) data in such format, that each row represents separate sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi everyone, Cosy bedroom in a modern apartment located in a central area, Paris 11th. * THE APARTMENT : it's a 2 bedrooms (one is mine) apartment of 47m2 (509 sq ft) fully renovated, warm atmosphere + a living room with a equiped kitchen, wifi. I provide towels and sheets * CENTRAL AREA : Cosmopolite, non-touristic, very close to the Marais, Bastille and Republic. * TRANSPORTS - 2 metro (3' walk) Saint Ambroise (line 9) or Richard Lenoir (line 5) - 2 city bike station Best J.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.Description\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi everyone, Cosy bedroom in a modern apartment located in a central area, Paris 11th',\n",
       " \" * THE APARTMENT : it's a 2 bedrooms (one is mine) apartment of 47m2 (509 sq ft) fully renovated, warm atmosphere + a living room with a equiped kitchen, wifi\",\n",
       " ' I provide towels and sheets * CENTRAL AREA : Cosmopolite, non-touristic, very close to the Marais, Bastille and Republic',\n",
       " \" * TRANSPORTS - 2 metro (3' walk) Saint Ambroise (line 9) or Richard Lenoir (line 5) - 2 city bike station Best J\",\n",
       " '']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0].split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [t.split('.') for t in text]\n",
    "\n",
    "with open('airbnb_sents.txt', 'w') as f:\n",
    "    for t in sents:\n",
    "        for s in t:\n",
    "            f.write(s)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi everyone, Cosy bedroom in a modern apartment located in a central area, Paris 11th\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 1 airbnb_sents.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run BPE, dictionary size = 1,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(79) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: airbnb_sents.txt\n",
      "  input_format: \n",
      "  model_prefix: airbnb_model_1\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.99\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(320) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(175) LOG(INFO) Loading corpus: airbnb_sents.txt\n",
      "trainer_interface.cc(376) LOG(INFO) Loaded all 684936 sentences\n",
      "trainer_interface.cc(391) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(391) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(391) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(396) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(457) LOG(INFO) all chars count=62484072\n",
      "trainer_interface.cc(468) LOG(INFO) Done: 99.0052% characters are covered.\n",
      "trainer_interface.cc(478) LOG(INFO) Alphabet size=55\n",
      "trainer_interface.cc(479) LOG(INFO) Final character coverage=0.990052\n",
      "trainer_interface.cc(511) LOG(INFO) Done! preprocessed 684337 sentences.\n",
      "unigram_model_trainer.cc(138) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(142) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(193) LOG(INFO) Initialized 203188 seed sentencepieces\n",
      "trainer_interface.cc(517) LOG(INFO) Tokenizing input sentences with whitespace: 684337\n",
      "trainer_interface.cc(527) LOG(INFO) Done! 220662\n",
      "unigram_model_trainer.cc(488) LOG(INFO) Using 220662 sentences for EM training\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=80559 obj=11.811 num_tokens=609901 num_tokens/piece=7.57086\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=71220 obj=9.50974 num_tokens=612770 num_tokens/piece=8.6039\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=53411 obj=9.47681 num_tokens=632158 num_tokens/piece=11.8357\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=53390 obj=9.47337 num_tokens=632776 num_tokens/piece=11.852\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=40042 obj=9.47729 num_tokens=661809 num_tokens/piece=16.5279\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=40041 obj=9.44047 num_tokens=661739 num_tokens/piece=16.5265\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=30030 obj=9.4205 num_tokens=694701 num_tokens/piece=23.1336\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=30030 obj=9.41406 num_tokens=694609 num_tokens/piece=23.1305\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=22522 obj=9.44479 num_tokens=730177 num_tokens/piece=32.4206\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=22522 obj=9.43591 num_tokens=730079 num_tokens/piece=32.4163\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=16891 obj=9.45833 num_tokens=768092 num_tokens/piece=45.4734\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=16891 obj=9.44654 num_tokens=768166 num_tokens/piece=45.4778\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=12668 obj=9.51141 num_tokens=808142 num_tokens/piece=63.794\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=12668 obj=9.49616 num_tokens=808435 num_tokens/piece=63.8171\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=9501 obj=9.57038 num_tokens=851173 num_tokens/piece=89.5877\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=9501 obj=9.5456 num_tokens=851395 num_tokens/piece=89.6111\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=7125 obj=9.66912 num_tokens=895200 num_tokens/piece=125.642\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=7125 obj=9.6434 num_tokens=895370 num_tokens/piece=125.666\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=5343 obj=9.79299 num_tokens=941575 num_tokens/piece=176.226\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=5343 obj=9.76029 num_tokens=941721 num_tokens/piece=176.253\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=4007 obj=9.97425 num_tokens=994856 num_tokens/piece=248.28\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=4007 obj=9.93087 num_tokens=995019 num_tokens/piece=248.32\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=3005 obj=10.2008 num_tokens=1042974 num_tokens/piece=347.08\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=3005 obj=10.1505 num_tokens=1043061 num_tokens/piece=347.108\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=2253 obj=10.4457 num_tokens=1093984 num_tokens/piece=485.568\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=2253 obj=10.3852 num_tokens=1094122 num_tokens/piece=485.629\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=1689 obj=10.7514 num_tokens=1149840 num_tokens/piece=680.782\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=1689 obj=10.6785 num_tokens=1149851 num_tokens/piece=680.788\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=1266 obj=11.1318 num_tokens=1201033 num_tokens/piece=948.683\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=1266 obj=11.0482 num_tokens=1201005 num_tokens/piece=948.661\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=1100 obj=11.2796 num_tokens=1228198 num_tokens/piece=1116.54\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=1100 obj=11.2339 num_tokens=1228274 num_tokens/piece=1116.61\n",
      "trainer_interface.cc(605) LOG(INFO) Saving model: airbnb_model_1.model\n",
      "trainer_interface.cc(616) LOG(INFO) Saving vocabs: airbnb_model_1.vocab\n",
      "CPU times: user 473 ms, sys: 187 ms, total: 660 ms\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! spm_train --input=airbnb_sents.txt --model_prefix=airbnb_model_1 --vocab_size=1000 --character_coverage=0.99--model_type=bpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~1 min was required to calculate the results, the higher compression rate (the lower size of the dictionary), the more time is required.\n",
    "\n",
    "We can encode the text with n-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁H i ▁every one , ▁Co s y ▁bedroom ▁in ▁a ▁modern ▁apartment ▁located ▁in ▁a ▁central ▁area , ▁Paris ▁1 1 th .\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"Hi everyone, Cosy bedroom in a modern apartment located in a central area, Paris 11th.\" | spm_encode --model=airbnb_model_1.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or with corresponding ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 29 592 305 5 270 4 19 68 11 8 278 37 109 11 8 347 89 5 417 65 177 71 0\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"Hi everyone, Cosy bedroom in a modern apartment located in a central area, Paris 11th.\" | spm_encode --model=airbnb_model_1.model --output_format=id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write our encoded data to train vowpall wabbit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('airbnb_texts.txt', 'w') as f:\n",
    "    for t in text:\n",
    "        f.write(t)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 ms, sys: 32.3 ms, total: 70.2 ms\n",
      "Wall time: 7.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!spm_encode --model=airbnb_model_1.model --output_format=id airbnb_texts.txt > airbnb_bpe_encoded.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 29 592 305 5 270 4 19 68 11 8 278 37 109 11 8 347 89 5 417 65 177 71 0 3 0 853 41 374 749 114 242 91 326 114 3 0 134 38 4 8 54 299 39 305 10 190 15 43 37 13 3 0 27 127 39 617 0 740 3 410 43 249 396 5 801 939 3 0 8 93 30 14 8 3 15 437 29 31 35 57 5 595 0 70 526 471 6 877 3 0 112 91 326 114 191 117 144 41 568 117 3 0 270 4 224 31 256 200 5 297 20 28 12 252 301 73 5 111 132 9 7 579 18 218 5 49 18 84 106 32 6 423 31 348 56 73 0 3 0 110 191 699 145 374 118 191 114 145 77 54 436 39 0 38 76 43 965 41 27 44 87 218 15 39 679 3 0 43 81 272 29 83 275 725 511 159 39 679 155 43 77 54 139 690 187 49 228 3 0\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 1 airbnb_bpe_encoded.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81406"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('airbnb_bpe_encoded.txt', 'r') as bpe:\n",
    "    encoded_texts = bpe.readlines()\n",
    "    \n",
    "len(encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_vw(raw_text, target):\n",
    "    return \"{} |d {}\".format(float(target), raw_text)\n",
    "        \n",
    "def write_vw(X_data, Y_data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for x, y in zip(X_data, Y_data):\n",
    "            vw_object = convert_to_vw(x, y)\n",
    "            if not vw_object:\n",
    "                continue\n",
    "            f.write(vw_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoded_texts, df.Price, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54542, 54542, 26864, 26864)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_vw(X_train, y_train, \"airbnb-train-bpe.vw\")\n",
    "write_vw(X_test, y_test, \"airbnb-test-bpe.vw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2 metric scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def read_target_from_vw(vw_object):\n",
    "    return float(vw_object.split(' ')[0])\n",
    "\n",
    "def calc_r2(predictions_path, answers_path):\n",
    "    with open(predictions_path, 'r') as f:\n",
    "        y_pred = np.array([float(value) for value in f.readlines()])\n",
    "        \n",
    "    with open(answers_path, 'r') as f:\n",
    "        y_expected = np.array([read_target_from_vw(value) for value in f.readlines()])\n",
    "\n",
    "        \n",
    "    return r2_score(y_expected, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = airbnb-lin-model-bpe.vw.bin\n",
      "Num weight bits = 23\n",
      "learning rate = 10\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = airbnb-train-bpe.vw.cache\n",
      "Reading datafile = airbnb-train-bpe.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "324.000000 324.000000            1            1.0  18.0000   0.0000      270\n",
      "438.408447 552.816895            2            2.0  48.0000  24.4879      302\n",
      "1115.257774 1792.107101            4            4.0 145.0000  87.5479      334\n",
      "4840.171246 8565.084717            8            8.0 110.0000 240.8061      303\n",
      "4695.488470 4550.805695           16           16.0 192.0000 255.6292      355\n",
      "6673.270553 8651.052636           32           32.0 403.0000 238.2178      319\n",
      "18521.320179 30369.369805           64           64.0  78.0000  58.0186      313\n",
      "26787.004926 35052.689673          128          128.0 189.0000 333.4107      456\n",
      "25499.102880 24211.200834          256          256.0  50.0000  36.4481       81\n",
      "26761.255206 28023.407531          512          512.0  50.0000 223.1980      315\n",
      "26617.142580 26473.029954         1024         1024.0 150.0000 141.0404      252\n",
      "24769.908473 22922.674366         2048         2048.0 125.0000 168.9110      299\n",
      "23459.677391 22149.446309         4096         4096.0 311.0000  73.2836       39\n",
      "21367.856047 19276.034703         8192         8192.0  85.0000 178.5537      374\n",
      "20706.585044 20045.314040        16384        16384.0 558.0000 146.3711      321\n",
      "19760.246777 18813.908511        32768        32768.0 120.0000  71.7101       91\n",
      "18525.400308 18525.400308        65536        65536.0 350.0000 137.2808      310 h\n",
      "17668.532738 16811.782837       131072       131072.0 105.0000 115.9399      334 h\n",
      "16856.943051 16045.297632       262144       262144.0  90.0000 113.5003      303 h\n",
      "16136.562569 15416.206820       524288       524288.0 139.0000 233.4878      356 h\n",
      "15544.954443 14953.356474      1048576      1048576.0  55.0000  96.9717      134 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 49088\n",
      "passes used = 30\n",
      "weighted example sum = 1472640.000000\n",
      "weighted label sum = 211641720.000000\n",
      "average loss = 14640.337891 h\n",
      "best constant = 143.715866\n",
      "total feature number = 369376110\n",
      "CPU times: user 40.2 ms, sys: 37.6 ms, total: 77.8 ms\n",
      "Wall time: 6.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! vw --final_regressor airbnb-lin-model-bpe.vw.bin airbnb-train-bpe.vw --passes 30 -l 10 -c -k --bit_precision 23 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = airbnb-1-predictions-bpe.txt\n",
      "Num weight bits = 23\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = airbnb-test-bpe.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "23058.980469 23058.980469            1            1.0 215.0000  63.1482      319\n",
      "14398.844482 5738.708496            2            2.0 189.0000 113.2457      277\n",
      "9505.072540 4611.300598            4            4.0  25.0000 116.8266      309\n",
      "16812.621964 24120.171387            8            8.0 698.0000 533.2416      354\n",
      "11089.064659 5365.507355           16           16.0  58.0000 102.7545      350\n",
      "12351.417374 13613.770089           32           32.0  50.0000  73.4964      370\n",
      "8441.588420 4531.759466           64           64.0  54.0000  86.7532      317\n",
      "14959.975895 21478.363370          128          128.0 245.0000 145.8976      207\n",
      "13014.284634 11068.593373          256          256.0 300.0000 144.4402      150\n",
      "14220.529146 15426.773659          512          512.0  78.0000 134.5945      322\n",
      "14760.134531 15299.739917         1024         1024.0 150.0000 169.1868      285\n",
      "13945.474506 13130.814481         2048         2048.0 135.0000 156.7252      277\n",
      "14644.752939 15344.031371         4096         4096.0  90.0000   0.0000      353\n",
      "14130.036537 13615.320136         8192         8192.0  35.0000 148.6762       73\n",
      "13693.111661 13256.186785        16384        16384.0 135.0000 120.8982      301\n",
      "\n",
      "finished run\n",
      "number of examples = 26864\n",
      "weighted example sum = 26864.000000\n",
      "weighted label sum = 3836739.000000\n",
      "average loss = 13937.427972\n",
      "best constant = 142.820831\n",
      "total feature number = 6731369\n"
     ]
    }
   ],
   "source": [
    "! vw --testonly --initial_regressor airbnb-lin-model-bpe.vw.bin --predictions airbnb-1-predictions-bpe.txt airbnb-test-bpe.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3283231885514082\n"
     ]
    }
   ],
   "source": [
    "print(calc_r2(\"airbnb-1-predictions-bpe.txt\", \"airbnb-test-bpe.vw\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality is almost the same as with \"raw\" tokens, but the model is trained faster and amount of features is less.\n",
    "\n",
    "Let's compare with linear regression from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()  \n",
    "X = vectorizer.fit_transform(encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected (:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df.Price, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.37 s, sys: 82.5 ms, total: 1.45 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "regressor = Ridge(solver='sparse_cg').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3376712432605553\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have much ligher model by using BPE and small increase of quality in comparison to linear regression on raw tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec\n",
    "\n",
    "Now we try to train word2vec model to get word vectors. Model is always trained on preprocessed texts, so we perform the same preprocessing as before: tokenization, punctuation and stop-words removal, stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk.data \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "words_only = re.compile('[a-z]+')\n",
    "\n",
    "def letters(s, regex = words_only):\n",
    "    if isinstance(s, str):\n",
    "        return words_only.findall(s.lower())\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def remove_stopwords(tokens, sw = stop_words):\n",
    "    return [t for t in tokens if not t in sw]\n",
    "\n",
    "def preprocess(s):\n",
    "    return remove_stopwords(letters(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "def stemm_description(d):\n",
    "    @lru_cache(maxsize=128)\n",
    "    def stemm_token(token):\n",
    "        return snowball.stem(token)\n",
    "\n",
    "    return [stemm_token(t) for t in d if len(stemm_token(t)) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f08e30984c34b8eb83267138cd6793b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81406.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afaddc955704c3297d0eada3fd70941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81406.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "      <th>lang</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71947</th>\n",
       "      <td>80.0</td>\n",
       "      <td>Bright apartment with a long terrace, 10 minutes from the Vatican museums and St. Peter (Vatican City). It's well connected to the center with a metro station (Cipro) 10 min by feet. The neighborhood is quiet, but full of shops, markets and several restaurants. The apartment has a spacious entrance with 2 armchairs, a dining room with kitchenette and other 2 armchairs, one can become an additional bed, fridge with freezer, microwave, TV, induction hob and oven, washing machine, iron. There are 2 bedrooms about 20 square meters, one with a king bed with a large desk, and the other one with 2 single beds and 2 desks (if necessary you can add an extra bed). Moreover the apartment has a bathroom and long balcony with a beautiful high (from the last floor) view of the city and the Vatican g...</td>\n",
       "      <td>en</td>\n",
       "      <td>[bright, apartment, long, terrace, minutes, vatican, museums, st, peter, vatican, city, well, connected, center, metro, station, cipro, min, feet, neighborhood, quiet, full, shops, markets, several, restaurants, apartment, spacious, entrance, armchairs, dining, room, kitchenette, armchairs, one, become, additional, bed, fridge, freezer, microwave, tv, induction, hob, oven, washing, machine, iron, bedrooms, square, meters, one, king, bed, large, desk, one, single, beds, desks, necessary, add, extra, bed, moreover, apartment, bathroom, long, balcony, beautiful, high, last, floor, view, city, vatican, gardens, great, spot, enjoy, summer, breeze, evening, kitchenette, everything, need, cooking, various, pots, meal, peacefully, bedrooms, dining, room, wood]</td>\n",
       "      <td>[bright, apart, long, terrac, minut, vatican, museum, peter, vatican, citi, well, connect, center, metro, station, cipro, min, feet, neighborhood, quiet, full, shop, market, sever, restaur, apart, spacious, entranc, armchair, dine, room, kitchenett, armchair, one, becom, addit, bed, fridg, freezer, microwav, induct, hob, oven, wash, machin, iron, bedroom, squar, meter, one, king, bed, larg, desk, one, singl, bed, desk, necessari, add, extra, bed, moreov, apart, bathroom, long, balconi, beauti, high, last, floor, view, citi, vatican, garden, great, spot, enjoy, summer, breez, even, kitchenett, everyth, need, cook, various, pot, meal, peac, bedroom, dine, room, wood]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Description lang                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  clean_text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              stems\n",
       "71947   80.0  Bright apartment with a long terrace, 10 minutes from the Vatican museums and St. Peter (Vatican City). It's well connected to the center with a metro station (Cipro) 10 min by feet. The neighborhood is quiet, but full of shops, markets and several restaurants. The apartment has a spacious entrance with 2 armchairs, a dining room with kitchenette and other 2 armchairs, one can become an additional bed, fridge with freezer, microwave, TV, induction hob and oven, washing machine, iron. There are 2 bedrooms about 20 square meters, one with a king bed with a large desk, and the other one with 2 single beds and 2 desks (if necessary you can add an extra bed). Moreover the apartment has a bathroom and long balcony with a beautiful high (from the last floor) view of the city and the Vatican g...   en  [bright, apartment, long, terrace, minutes, vatican, museums, st, peter, vatican, city, well, connected, center, metro, station, cipro, min, feet, neighborhood, quiet, full, shops, markets, several, restaurants, apartment, spacious, entrance, armchairs, dining, room, kitchenette, armchairs, one, become, additional, bed, fridge, freezer, microwave, tv, induction, hob, oven, washing, machine, iron, bedrooms, square, meters, one, king, bed, large, desk, one, single, beds, desks, necessary, add, extra, bed, moreover, apartment, bathroom, long, balcony, beautiful, high, last, floor, view, city, vatican, gardens, great, spot, enjoy, summer, breeze, evening, kitchenette, everything, need, cooking, various, pots, meal, peacefully, bedrooms, dining, room, wood]  [bright, apart, long, terrac, minut, vatican, museum, peter, vatican, citi, well, connect, center, metro, station, cipro, min, feet, neighborhood, quiet, full, shop, market, sever, restaur, apart, spacious, entranc, armchair, dine, room, kitchenett, armchair, one, becom, addit, bed, fridg, freezer, microwav, induct, hob, oven, wash, machin, iron, bedroom, squar, meter, one, king, bed, larg, desk, one, singl, bed, desk, necessari, add, extra, bed, moreov, apart, bathroom, long, balconi, beauti, high, last, floor, view, citi, vatican, garden, great, spot, enjoy, summer, breez, even, kitchenett, everyth, need, cook, various, pot, meal, peac, bedroom, dine, room, wood]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "with Pool(8) as p:\n",
    "    clean_text = list(tqdm(p.imap(preprocess, df.Description), total=len(df)))\n",
    "    \n",
    "df['clean_text'] = clean_text\n",
    "    \n",
    "with Pool(8) as p:\n",
    "    stems = list(tqdm(p.imap(stemm_description, df.clean_text), total=len(df)))\n",
    "    \n",
    "df['stems'] = stems\n",
    "\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_for_vector_models.txt', 'w') as f:\n",
    "    for s in df.stems:\n",
    "        f.write(' '.join(s))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main model params:\n",
    "\n",
    "* size — vector size, \n",
    "* window — size of the observation window,\n",
    "* min_count — minimum word frequency in the corpora (not equal to 0 by default!),\n",
    "* sg — learning algorithm to use (0 — CBOW, 1 — Skip-gram),\n",
    "* sample — threshold for downsampling of high frequency words,\n",
    "* workers — amount of threads,\n",
    "* alpha — learning rate,\n",
    "* iter — iterations count,\n",
    "* max_vocab_size — allows to limit used RAM for dictionary creation (in case of limit violation the lowest words by frequence would be dropped out from the dictionary). For example: 10 mln of words = 1Gb of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 0 ns, total: 1min 18s\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "%time w2v_model = word2vec.Word2Vec(df.stems, workers=4, size=300, min_count=10, window=4, sample=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you work with large texts collection, which does not fit into memory, we can use an iterator as dataset loader object (file format is the same as sentencepiece: one row = one sentence, words are split by spaces; possible to have several files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences_w2v.txt', 'w') as f:\n",
    "    for s in df.stems:\n",
    "        f.write(' '.join(s)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everyon cosi bedroom modern apart locat central area pari apart bedroom one mine apart fulli renov warm atmospher live room equip kitchen wifi provid towel sheet central area cosmopolit non tourist close marai bastill republ transport metro walk saint ambrois line richard lenoir line citi bike station best\r\n",
      "comfort calm apart room center pari bastill area welcom explain live area bakeri market restaur bar live build close public transport metro ledru rollin charonn bastill gare lyon bus germain louvr gare austerlitz gare nord live room bedroom kitchen bathroom sleep person doubl bed sofa bed also divid separ part quiet apart direct opposit love park central locat live restaur cafe fruit market live build love area nice vie quartier market bakeri apart equip fulli equip kitchen refriger freezer toaster kettl microwav induct hob dishwash wash machin coffe maker sheet towel linen provid broadband internet adsl\r\n",
      "minut walk publiqu oberkampf nilmont lachais rent flat includ shower room toilet equip kitchen coffe machin box dvd tabl internet access easi disneyland rent littl full equip flat right near publiqu avenu minut walk publiqu oberkampf lachais bastill marai right near metro line walk minut find supermarket coffe mani restaur bakeri hair cutter need studio small kitchen bathroom toilet cabl free wifi access studio minut station saint maur minut supermarket near close line district anim famous oberkampf saint maur street minut walk republiqu minut acc des voyageur les locatair ont acc tou\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 sentences_w2v.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 0 ns, total: 1min 23s\n",
      "Wall time: 43.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "\n",
    "class Sentences(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    " \n",
    "    def __iter__(self):\n",
    "            for line in open(self.filename, 'r'):\n",
    "                yield line.split()\n",
    " \n",
    "\n",
    "sents = Sentences('sentences_w2v.txt') \n",
    "model_f = word2vec.Word2Vec(sents, workers=4, size=300, min_count=10, window=4, sample=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the closest word's neighbours (model is trained on stemms):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bedroom', 0.6954348087310791), ('larg', 0.5923123359680176), ('bathroom', 0.5694455504417419), ('adjoin', 0.5647478103637695), ('livingroom', 0.5623283982276917)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.wv.most_similar(positive=[\"room\"], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('clawfoot', 0.6027348041534424), ('sink', 0.5912506580352783), ('vaniti', 0.5649619102478027), ('bathtub', 0.546120285987854), ('rainshow', 0.5302311182022095)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.wv.most_similar(positive=[\"shower\"], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sink', 0.5929206609725952), ('clawfoot', 0.5884297490119934), ('vaniti', 0.5783952474594116), ('bathtub', 0.5565468668937683), ('washbasin', 0.5494244694709778)]\n"
     ]
    }
   ],
   "source": [
    "print(model_f.wv.most_similar(positive=[\"shower\"], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'large' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-8dd6f4129b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"large\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'large' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "print(w2v_model.wv.most_similar(positive=[\"large\"], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem of the word2vec model - out of vocabulary words, which are not included into training dataset (in our case because we use stemms).\n",
    "\n",
    "Let's train linear regression: first we have to get vector for descriptions by averaging the words' vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(list(word2vec.values())[0])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = dict(zip(w2v_model.wv.index2word, w2v_model.wv.vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "regressor = Ridge(solver='sparse_cg')\n",
    "\n",
    "w2v_pipeline = Pipeline([\n",
    "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v)),\n",
    "    (\"regressor\", regressor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.stems, df.Price, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 s, sys: 12.1 s, total: 43.3 s\n",
      "Wall time: 23.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('word2vec vectorizer',\n",
       "                 <__main__.MeanEmbeddingVectorizer object at 0x7f34868c5520>),\n",
       "                ('regressor', Ridge(solver='sparse_cg'))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "w2v_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24305641736730677\n"
     ]
    }
   ],
   "source": [
    "y_pred = w2v_pipeline.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not impressive, probably, the problem is that we take all words with same weight, let's weight them with tf-idf coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(list(word2vec.values())[0])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter,defaultdict\n",
    "\n",
    "regressor = Ridge(solver='sparse_cg')\n",
    "\n",
    "w2v_tfidf_pipeline = Pipeline([\n",
    "    (\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v)),\n",
    "    (\"regressor\", regressor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 19.9 s, total: 1min 26s\n",
      "Wall time: 55.6 s\n",
      "0.2734952616211819\n"
     ]
    }
   ],
   "source": [
    "%time w2v_tfidf_pipeline.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = w2v_tfidf_pipeline.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better than mean vector, but still a room for improvement!\n",
    "\n",
    "Let's try fastText model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 45s, sys: 5.96 s, total: 11min 51s\n",
      "Wall time: 5min 58s\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "\n",
    "%time ft_model = fasttext.train_unsupervised('sentences_w2v.txt', minn=3, maxn=4, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7296572923660278, 'bathroom'),\n",
       " (0.7287658452987671, 'bedroom'),\n",
       " (0.6851889491081238, 'bdroom'),\n",
       " (0.6800824403762817, 'bedrooom'),\n",
       " (0.6773774027824402, 'boxroom'),\n",
       " (0.6652435064315796, 'bathrooom'),\n",
       " (0.6594610214233398, 'rooom'),\n",
       " (0.6421788334846497, 'live'),\n",
       " (0.6419817209243774, 'mudroom'),\n",
       " (0.6401411890983582, 'spacious')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_nearest_neighbors('room')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more out of vocabulary words problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6229067444801331, 'hot'),\n",
       " (0.6198985576629639, 'hotdog'),\n",
       " (0.605341374874115, 'hottub'),\n",
       " (0.5855438709259033, 'hote'),\n",
       " (0.5623665452003479, 'hotpot'),\n",
       " (0.5119271874427795, 'notr'),\n",
       " (0.5116435885429382, 'hottest'),\n",
       " (0.510097324848175, 'hotter'),\n",
       " (0.48678746819496155, 'hothous'),\n",
       " (0.48394525051116943, 'dame')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_nearest_neighbors('hotrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanFTEmbeddingVectorizer(object):\n",
    "    def __init__(self, ft_model):\n",
    "        self.ft_model = ft_model\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.ft_model[w] for w in words ]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Ridge(solver='sparse_cg')\n",
    "\n",
    "ft_pipeline = Pipeline([\n",
    "    (\"fasttext vectorizer\", MeanFTEmbeddingVectorizer(ft_model)),\n",
    "    (\"regressor\", regressor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.8 s, sys: 2.85 s, total: 40.6 s\n",
      "Wall time: 36.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('fasttext vectorizer',\n",
       "                 <__main__.MeanFTEmbeddingVectorizer object at 0x7f34bbe163a0>),\n",
       "                ('regressor', Ridge(solver='sparse_cg'))])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "ft_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3504588499177357\n"
     ]
    }
   ],
   "source": [
    "y_pred = ft_pipeline.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than word2vec !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
